name: adam
method: grid
metric:
  name: val/loss
  goal: minimize

parameters:
  optim.learning_rate:
    values: [5e-4, 6e-4, 9e-4, 1.3e-3, 1.8e-3, 2.5e-3, 3.5e-3, 5e-3, 7e-3, 9e-3]

command:
  - torchrun
  - --standalone
  - --nproc_per_node=4
  - train_gpt2.py
  - ${args_no_hyphens}
  - optim=adamw
  - wandb_log=1
  - max_iters=10000
  - optim.decay=0
  - "exp_name=adam_lr${optim.learning_rate}"